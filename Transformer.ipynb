{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Transformer.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"149Nfz-lGqpG8EZyDyiQzZTiQGwCsAQOe","authorship_tag":"ABX9TyNXehxgf6z3wn0QaXMNtUsg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"yuqNAocU9So_"},"source":["## Transformer"]},{"cell_type":"code","metadata":{"id":"6dTRylHH9SKv","executionInfo":{"status":"ok","timestamp":1628966575026,"user_tz":-330,"elapsed":1835,"user":{"displayName":"Dristanta Das","photoUrl":"","userId":"05395526362301802286"}}},"source":["import numpy as np\n","import tensorflow as tf"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"7gkMXquy9RtO","executionInfo":{"status":"ok","timestamp":1628966576930,"user_tz":-330,"elapsed":1908,"user":{"displayName":"Dristanta Das","photoUrl":"","userId":"05395526362301802286"}}},"source":["def get_angles(pos, i, d_model):\n","    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n","    return pos * angle_rates\n","\n","\n","def positional_encoding(position, d_model):\n","    angle_rads = get_angles(\n","        np.arange(position)[:, np.newaxis], np.arange(d_model)[np.newaxis, :], d_model\n","    )\n","\n","    # apply sin to even indices in the array; 2i\n","    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n","\n","    # apply cos to odd indices in the array; 2i+1\n","    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n","\n","    pos_encoding = angle_rads[np.newaxis, ...]\n","\n","    return tf.cast(pos_encoding, dtype=tf.float32)\n","\n","\n","def scaled_dot_product_attention(q, k, v, mask):\n","    \"\"\"Calculate the attention weights.\n","    q, k, v must have matching leading dimensions.\n","    k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n","    The mask has different shapes depending on its type(padding or look ahead)\n","    but it must be broadcastable for addition.\n","    Args:\n","      q: query shape == (..., seq_len_q, depth)\n","      k: key shape == (..., seq_len_k, depth)\n","      v: value shape == (..., seq_len_v, depth_v)\n","      mask: Float tensor with shape broadcastable\n","            to (..., seq_len_q, seq_len_k). Defaults to None.\n","    Returns:\n","      output, attention_weights\n","    \"\"\"\n","\n","    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n","\n","    # scale matmul_qk\n","    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n","    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n","\n","    # add the mask to the scaled tensor.\n","    if mask is not None:\n","        scaled_attention_logits += mask * -1e9\n","\n","        # softmax is normalized on the last axis (seq_len_k) so that the scores\n","    # add up to 1.\n","    attention_weights = tf.nn.softmax(\n","        scaled_attention_logits, axis=-1\n","    )  # (..., seq_len_q, seq_len_k)\n","\n","    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n","\n","    return output, attention_weights\n","\n","\n","class MultiHeadAttention(tf.keras.layers.Layer):\n","    def __init__(self, d_model, num_heads):\n","        super(MultiHeadAttention, self).__init__()\n","        self.num_heads = num_heads\n","        self.d_model = d_model\n","\n","        assert d_model % self.num_heads == 0\n","\n","        self.depth = d_model // self.num_heads\n","\n","        self.wq = tf.keras.layers.Dense(d_model)\n","        self.wk = tf.keras.layers.Dense(d_model)\n","        self.wv = tf.keras.layers.Dense(d_model)\n","\n","        self.dense = tf.keras.layers.Dense(d_model)\n","\n","    def split_heads(self, x, batch_size):\n","        \"\"\"Split the last dimension into (num_heads, depth).\n","        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n","        \"\"\"\n","        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n","        return tf.transpose(x, perm=[0, 2, 1, 3])\n","\n","    def call(self, v, k, q, mask=None):\n","        batch_size = tf.shape(q)[0]\n","\n","        q = self.wq(q)  # (batch_size, seq_len, d_model)\n","        k = self.wk(k)  # (batch_size, seq_len, d_model)\n","        v = self.wv(v)  # (batch_size, seq_len, d_model)\n","\n","        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n","        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n","        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n","\n","        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n","        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n","        scaled_attention, attention_weights = scaled_dot_product_attention(\n","            q, k, v, mask\n","        )\n","\n","        scaled_attention = tf.transpose(\n","            scaled_attention, perm=[0, 2, 1, 3]\n","        )  # (batch_size, seq_len_q, num_heads, depth)\n","\n","        concat_attention = tf.reshape(\n","            scaled_attention, (batch_size, -1, self.d_model)\n","        )  # (batch_size, seq_len_q, d_model)\n","\n","        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n","\n","        return output, attention_weights\n","\n","\n","def point_wise_feed_forward_network(d_model, dff):\n","    return tf.keras.Sequential(\n","        [\n","            tf.keras.layers.Dense(dff, activation=\"relu\"),  # (batch_size, seq_len, dff)\n","            tf.keras.layers.Dense(d_model),  # (batch_size, seq_len, d_model)\n","        ]\n","    )\n","\n","\n","class EncoderLayer(tf.keras.layers.Layer):\n","    def __init__(self, d_model, num_heads, dff, rate=0.1):\n","        super(EncoderLayer, self).__init__()\n","\n","        self.mha = MultiHeadAttention(d_model, num_heads)\n","        self.ffn = point_wise_feed_forward_network(d_model, dff)\n","\n","        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","\n","        self.dropout1 = tf.keras.layers.Dropout(rate)\n","        self.dropout2 = tf.keras.layers.Dropout(rate)\n","\n","    def call(self, x, training=None, mask=None):\n","        attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n","        attn_output = self.dropout1(attn_output, training=training)\n","        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n","\n","        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n","        ffn_output = self.dropout2(ffn_output, training=training)\n","        out2 = self.layernorm2(\n","            out1 + ffn_output\n","        )  # (batch_size, input_seq_len, d_model)\n","\n","        return out2\n","\n","\n","class Encoder(tf.keras.layers.Layer):\n","    def __init__(\n","        self, num_layers, d_model, num_heads, dff, maximum_position_encoding, rate=0.1,\n","    ):\n","        super(Encoder, self).__init__()\n","\n","        self.d_model = d_model\n","        self.num_layers = num_layers\n","\n","        self.pos_encoding = positional_encoding(maximum_position_encoding, self.d_model)\n","\n","        self.enc_layers = [\n","            EncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)\n","        ]\n","\n","        self.dropout = tf.keras.layers.Dropout(rate)\n","\n","    def call(self, x, training=None, mask=None):\n","        seq_len = tf.shape(x)[1]\n","\n","        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n","        x += self.pos_encoding[:, :seq_len, :]\n","\n","        x = self.dropout(x, training=training)\n","\n","        for i in range(self.num_layers):\n","            x = self.enc_layers[i](x, training, mask)\n","\n","        return x  # (batch_size, input_seq_len, d_model)\n","\n","\n","class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n","    def __init__(self, d_model, warmup_steps=4000, name=None):\n","        super(CustomSchedule, self).__init__()\n","\n","        self.d_model = d_model\n","        self.d_model = tf.cast(self.d_model, tf.float32)\n","\n","        self.warmup_steps = warmup_steps\n","        self.name = name  # Modified from the source\n","\n","    def __call__(self, step):\n","        arg1 = tf.math.rsqrt(step)\n","        arg2 = step * (self.warmup_steps ** -1.5)\n","\n","        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n","\n","    def get_config(self):  # Modified from the source\n","        return {\n","            \"d_model\": self.d_model,\n","            \"warmup_steps\": self.warmup_steps,\n","            \"name\": self.name,\n","        }"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"mQLOdYds9Rne","executionInfo":{"status":"ok","timestamp":1628966576931,"user_tz":-330,"elapsed":8,"user":{"displayName":"Dristanta Das","photoUrl":"","userId":"05395526362301802286"}}},"source":[""],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"I0-yER4A9Rg_","executionInfo":{"status":"ok","timestamp":1628966576932,"user_tz":-330,"elapsed":8,"user":{"displayName":"Dristanta Das","photoUrl":"","userId":"05395526362301802286"}}},"source":[""],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"BS68lp7V9QvP","executionInfo":{"status":"ok","timestamp":1628966576932,"user_tz":-330,"elapsed":7,"user":{"displayName":"Dristanta Das","photoUrl":"","userId":"05395526362301802286"}}},"source":[""],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"LiZf-H_Y9OV-","executionInfo":{"status":"ok","timestamp":1628966576932,"user_tz":-330,"elapsed":7,"user":{"displayName":"Dristanta Das","photoUrl":"","userId":"05395526362301802286"}}},"source":[""],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pHmo9X1T63hz"},"source":["## Model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i-pZdeTG6pNp","executionInfo":{"status":"ok","timestamp":1628966588132,"user_tz":-330,"elapsed":3790,"user":{"displayName":"Dristanta Das","photoUrl":"","userId":"05395526362301802286"}},"outputId":"ae93e033-3236-4175-c03e-3b7300d8f87a"},"source":["!pip install transformer-encoder\n","from tensorflow.keras.layers import (\n","    Input,\n","    GlobalAvgPool1D,\n","    Dense,\n","    Bidirectional,\n","    GRU,\n","    Dropout,\n",")\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.python.framework import ops\n","from tensorflow.python.keras import backend as K\n","from tensorflow.python.ops import clip_ops\n","from tensorflow.python.ops import math_ops\n","from tensorflow.keras.losses import mae\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting transformer-encoder\n","  Downloading transformer_encoder-0.0.3-py3-none-any.whl (9.0 kB)\n","Installing collected packages: transformer-encoder\n","Successfully installed transformer-encoder-0.0.3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8rcWZgE-69v_","executionInfo":{"status":"ok","timestamp":1628966591843,"user_tz":-330,"elapsed":566,"user":{"displayName":"Dristanta Das","photoUrl":"","userId":"05395526362301802286"}}},"source":["def custom_binary_accuracy(y_true, y_pred, threshold=0.5):\n","    threshold = math_ops.cast(threshold, y_pred.dtype)\n","    y_pred = math_ops.cast(y_pred > threshold, y_pred.dtype)\n","    y_true = math_ops.cast(y_true > threshold, y_true.dtype)\n","\n","    return K.mean(math_ops.equal(y_true, y_pred), axis=-1)\n","\n","\n","def custom_binary_crossentropy(y_true, y_pred):\n","    y_pred = ops.convert_to_tensor(y_pred)\n","    y_true = math_ops.cast(y_true, y_pred.dtype)\n","    epsilon_ = K._constant_to_tensor(K.epsilon(), y_pred.dtype.base_dtype)\n","    output = clip_ops.clip_by_value(y_pred, epsilon_, 1.0 - epsilon_)\n","\n","    # Compute cross entropy from probabilities.\n","    bce = 4 * y_true * math_ops.log(output + K.epsilon())\n","    bce += (1 - y_true) * math_ops.log(1 - output + K.epsilon())\n","    return K.sum(-bce, axis=-1)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"x3PwDHXx8BB0","executionInfo":{"status":"ok","timestamp":1628966644048,"user_tz":-330,"elapsed":554,"user":{"displayName":"Dristanta Das","photoUrl":"","userId":"05395526362301802286"}}},"source":["def transformer_classifier(\n","                            num_layers=4,\n","                            d_model=16822,\n","                            num_heads=13,\n","                            dff=256,\n","                            maximum_position_encoding=2048,\n","                            n_classes=16,\n","                            ):\n","    inp = Input((None, d_model))\n","    encoder = Encoder(\n","                        num_layers=num_layers,\n","                        d_model=d_model,\n","                        num_heads=num_heads,\n","                        dff=dff,\n","                        maximum_position_encoding=maximum_position_encoding,\n","                        rate=0.3,\n","                    )\n","    x = encoder(inp)\n","    x = Dropout(0.2)(x)\n","    x = GlobalAvgPool1D()(x)\n","    x = Dense(4 * n_classes, activation=\"selu\")(x)\n","    out = Dense(n_classes, activation=\"sigmoid\")(x)\n","    model = Model(inputs=inp, outputs=out)\n","    opt = Adam(0.00001)\n","    model.compile(optimizer=opt, loss=custom_binary_crossentropy, metrics=[custom_binary_accuracy])\n","    model.summary()\n","    return model"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"kifm16pR8b8a"},"source":["transformer_classifier()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f43YUwtQ8h2l"},"source":["def transformer_pretrain(\n","                        num_layers=4, d_model=16822, num_heads=13, dff=256, maximum_position_encoding=2048,\n","                        ):\n","    inp = Input((None, d_model))\n","    encoder = Encoder(\n","        num_layers=num_layers,\n","        d_model=d_model,\n","        num_heads=num_heads,\n","        dff=dff,\n","        maximum_position_encoding=maximum_position_encoding,\n","        rate=0.3,\n","    )\n","    x = encoder(inp)\n","    out = Dense(d_model, activation=\"linear\", name=\"out_pretraining\")(x)\n","    model = Model(inputs=inp, outputs=out)\n","    opt = Adam(0.0001)\n","    model.compile(optimizer=opt, loss=mae)\n","    model.summary()\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R-Yp_Igh-Kdl","executionInfo":{"status":"ok","timestamp":1628329007683,"user_tz":-330,"elapsed":1438,"user":{"displayName":"Dristanta Das","photoUrl":"","userId":"05395526362301802286"}},"outputId":"3493a6fb-36c6-4bd0-b134-6ac2726334ce"},"source":["transformer_pretrain()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_4 (InputLayer)         [(None, None, 128)]       0         \n","_________________________________________________________________\n","encoder_1 (Encoder)          (None, None, 128)         529920    \n","_________________________________________________________________\n","out_pretraining (Dense)      (None, None, 128)         16512     \n","=================================================================\n","Total params: 546,432\n","Trainable params: 546,432\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.engine.functional.Functional at 0x7f359f421c50>"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"1whS4IAC-NIX"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pl0Xby5HFDe2"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b3ZzJ2bsFDwf"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m8OX-7kmFD39"},"source":["import numpy as np\n","import librosa\n","from scipy import signal\n","from scipy.io import wavfile\n","from scipy.signal import butter,filtfilt\n","from scipy.stats import kurtosis\n","import scipy.signal as signal\n","from scipy.integrate import simps\n","import matplotlib.pyplot as plt\n","import librosa.display\n","import sklearn\n","import pandas as pd\n","import seaborn as sns\n","import json"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lqQglFF4FJta"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VTnJMseWFMvD"},"source":["## Loading the Data"]},{"cell_type":"code","metadata":{"id":"X2sAeK6-FPKj"},"source":["def load_data(data_path):\n","    with open(data_path,\"r\") as fp:\n","        data=json.load(fp)\n","    inputs = np.array(data[\"mfcc\"])\n","    targets= np.array(data[\"labels\"])\n","    \n","    return inputs,targets"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zkFZKaxDFS3m","executionInfo":{"status":"ok","timestamp":1628330881690,"user_tz":-330,"elapsed":7814,"user":{"displayName":"Dristanta Das","photoUrl":"","userId":"05395526362301802286"}},"outputId":"f86e7bd2-8e74-4a2f-aa16-f9c3691d82ad"},"source":["inputs,targets=load_data(\"/content/drive/MyDrive/mfcc_3.json\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  after removing the cwd from sys.path.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"WMejggl4FVF4"},"source":["shape_diff=[]\n","for i in range(len(inputs)):\n","    shape_diff.append(np.array(inputs[i]).shape[0])\n","\n","INPUTS2=inputs.copy()\n","\n","INPUTS3=[]\n","for i in range(INPUTS2.shape[0]):\n","  A=np.zeros((max(shape_diff),13))#-np.array(INPUTS2[i]).shape[0]\n","  A[:np.array(INPUTS2[i]).shape[0],:]=INPUTS2[i]\n","  INPUTS3.append(A)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PMsQRYbwFd3t"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6JPE_ztwFmfJ"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1-Cg__P8Fm2Z"},"source":["## Train Test Split"]},{"cell_type":"code","metadata":{"id":"oow9s-VNFoVS"},"source":["from sklearn.model_selection import train_test_split"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YtHRJRE_Fqjc"},"source":["def prepare_dataset(test_size,val_size):\n","  X_train,X_test,y_train,y_test=train_test_split(INPUTS3,targets,test_size=test_size)\n","  X_train,X_valid,y_train,y_valid=train_test_split(X_train,y_train,test_size=val_size)\n","\n","  return np.array(X_train),np.array(X_valid),np.array(X_test),y_train,y_valid,y_test"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G4an8ZFHFs79"},"source":["X_train,X_valid,X_test,y_train,y_valid,y_test= prepare_dataset(0.25,0.2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vTFjhgirGU4K"},"source":["## Using The Model"]},{"cell_type":"code","metadata":{"id":"B-OYY3zdGXHU"},"source":["from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pwv_RtNTGgcp"},"source":["h5_name = \"transformer_v2.h5\"\n","h5_pretrain = \"transformer_pretrain.h5\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3ScgVQzwIW60","executionInfo":{"status":"ok","timestamp":1628331828386,"user_tz":-330,"elapsed":483,"user":{"displayName":"Dristanta Das","photoUrl":"","userId":"05395526362301802286"}},"outputId":"ce218d11-23b1-47b7-da67-a17f72861c24"},"source":["input_shape=(X_train.shape[1],X_train.shape[2])\n","print(type(input_shape))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["<class 'tuple'>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LazaTiczFv9X","executionInfo":{"status":"ok","timestamp":1628332420392,"user_tz":-330,"elapsed":1384,"user":{"displayName":"Dristanta Das","photoUrl":"","userId":"05395526362301802286"}},"outputId":"8c639d42-1874-4262-8bfd-bc03bb9eca95"},"source":["model = transformer_classifier(n_classes=2)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model_4\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_10 (InputLayer)        [(None, None, 128)]       0         \n","_________________________________________________________________\n","encoder_6 (Encoder)          (None, None, 128)         529920    \n","_________________________________________________________________\n","dropout_66 (Dropout)         (None, None, 128)         0         \n","_________________________________________________________________\n","global_average_pooling1d_3 ( (None, 128)               0         \n","_________________________________________________________________\n","dense_174 (Dense)            (None, 8)                 1032      \n","_________________________________________________________________\n","dense_175 (Dense)            (None, 2)                 18        \n","=================================================================\n","Total params: 530,970\n","Trainable params: 530,970\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sFd-ztLmFyYw"},"source":["checkpoint = ModelCheckpoint(\n","    h5_name,\n","    monitor=\"val_loss\",\n","    verbose=1,\n","    save_best_only=True,\n","    mode=\"min\",\n","    save_weights_only=True,\n",")\n","reduce_o_p = ReduceLROnPlateau(\n","    monitor=\"val_loss\", patience=20, min_lr=1e-7, mode=\"min\"\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IvDeE-bKG7VP"},"source":["epochs=1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":714},"id":"n3hO8HvEGMct","executionInfo":{"status":"error","timestamp":1628332430617,"user_tz":-330,"elapsed":5,"user":{"displayName":"Dristanta Das","photoUrl":"","userId":"05395526362301802286"}},"outputId":"816fd63a-ebb0-47f0-ad48-999b14adf1d9"},"source":[" model.fit(\n","        X_train,y_train,\n","        validation_data=(X_valid,y_valid),\n","        epochs=epochs,\n","        callbacks=[checkpoint, reduce_o_p],\n","        use_multiprocessing=True,\n","        workers=12,\n","        verbose=2,\n","        max_queue_size=64,\n","    )"],"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-55-2aae937dab05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m        \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m        \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m        \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m    )\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    762\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    763\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 764\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3048\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3049\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3050\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3051\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3444\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3445\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3287\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3288\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3289\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3290\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    984\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:855 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:845 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:838 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:795 train_step\n        y_pred = self(x, training=True)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:1013 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/input_spec.py:270 assert_input_compatibility\n        ', found shape=' + display_shape(x.shape))\n\n    ValueError: Input 0 is incompatible with layer model_4: expected shape=(None, None, 128), found shape=(None, 1294, 13)\n"]}]},{"cell_type":"code","metadata":{"id":"K2Pndw1oG5bu"},"source":[""],"execution_count":null,"outputs":[]}]}